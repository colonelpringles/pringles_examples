{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Pringles__, _a documentation_, __part 2__\n",
    "\n",
    "In this document about pringles we will show: \n",
    "- model metadata parsing\n",
    "- a more large-scale model\n",
    "- working with some python libraries to build the model\n",
    "- run the simulation doing some parameter sweeping\n",
    "- use pandas, matplotlib and some pringles's helpers to analyze the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "- Run the command below. It will remove any previous user_models, generate the atomic source we will use in this tutorial, and build CD++.\n",
    "- Check that you have the python dependencies installed. See `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# This is the magic command.\n",
    "!rm -rf user_models/* && mkdir -p user_models/ && cd generator/ && python model_generator.py -o ../user_models -c ../../cdpp/src -m 20 && make -C ../user_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What model is on the menu?\n",
    "**Graphs!** This demo will be all about graphs. Graphs seems like a really nice abstraction that can be applied to several systems / phenoma we might want to simulate. \n",
    "\n",
    "In this case, it's not a generic graph, because that wouldn't be interesting to simulate. Our model is called a **Graph based SIR**, it models the number of people infected with a contagious illness in a closed population over time. SIR stands for **S**uceptible, **I**nfected and **R**ecovered. That said, each node in the graph will be an individual that might start intfected or not, according to a parameter we have in our model called *infection_prob*. When a simulation is initiated, the Node will flip a coin, and will become infected with $P(startsInfected)=valueOf(infection\\_prob)$. Once started, we have two possibilities, depending on how the model initiates:\n",
    "\n",
    "![Authomata like Node description](resources/graph_based_SIR.png \"Authomata like Node description\")\n",
    "\n",
    "In the image above, you can se how each parameter of node affects its behaviour.\n",
    "\n",
    "Also, it's nice to work with some graph generation and analysis library: networkx. We will work with it, and integrate it with pringles.\n",
    "\n",
    "Let's start by instantiating the Simulator, and saving the *registry* in an easy access variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pringles.simulator import Simulator, Simulation\n",
    "from pringles.models import Coupled\n",
    "from pringles.utils import VirtualTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the simulator, targeting our own CD++ distribution (obviously with the atomics we are about to use compiled and registered in it),\n",
    "#  and the Atomics directory, from which to extact the __Model Metadata__. A bit more on this below.\n",
    "simulator = Simulator(cdpp_bin_path=\"user_models/bin\", user_models_dir=\"user_models/\")\n",
    "\n",
    "# Get the Atomic models registry in an easy accessible variable, such as 'r'. Short and concise right?\n",
    "r = simulator.get_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at something interesting. What does targeting the directory where our model sources are located is worth for?\n",
    "\n",
    "Pringles uses some structured comments we defined in the source files of each model, to instantiate the classes of them for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  \".join([dict_item for dict_item in dir(r) if not dict_item.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those NodeN, with N a number, are our node models. Their classes and ports have been already loaded into the pringles registry.\n",
    "\n",
    "Below, you'll find a detailed explanation of model metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.Node5(\"test\").get_port(\"in4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Metadata\n",
    "\n",
    "Let's suppose that you don't know about this model metadata thingy, and that you only have one atomic model in the simulator called __Queue__.\n",
    "In that case, for it to be accessible from pringles, you would have to define a class, inheriting from Atomic. Furthermore, you would need to declare by hand each port the model has.\n",
    "\n",
    "Let's see the __Queue__ example, assuming it just has two input ports, __job__ and __ready___; and one output port, __jobs_status__ .\n",
    "\n",
    "```python\n",
    "from pringles.models import Atomic\n",
    "\n",
    "class Queue(Atomic):\n",
    "    def __init__(self, name: str, **model_params: str):\n",
    "        super().__init__(name, **model_params)\n",
    "        self.add_output_port(\"job_status\")\n",
    "        self.add_input_port(\"job\")\n",
    "        self.add_input_port(\"ready\")\n",
    "```\n",
    "\n",
    "In my opinion, it's annoying having to write the whole constructor over and over for each Atomic one has already written in C++. Wouldn't it be nice if __pringles__ could read somehow the C++ model implementation?\n",
    "\n",
    "That's when __model metadata__ comes handy!\n",
    "\n",
    "Model metadata is a comment format we defined for you to write over each header file of each Atomic you want for pringles to discover. Let's say (following the prior example) you want the _queue_ to be discovered. In that case, you'd just go to _queue.h_, and somewhere on the file (preferrably over the class definition, just for setting a convention) and add a comment like this one:\n",
    "\n",
    "```c++\n",
    "/*\n",
    "@PringlesModelMetadata\n",
    "name:   Queue\n",
    "input_ports: job, ready\n",
    "output_ports: job_status\n",
    "*/\n",
    "\n",
    "class Queue : public Atomic {\n",
    "    /*\n",
    "    All you lovely CD++ queue impl.\n",
    "    */\n",
    "}\n",
    "```\n",
    "\n",
    "Let's analyze the syntax a little more, just to be clear:\n",
    "\n",
    "```c++\n",
    "/*\n",
    "@PringlesModelMetadata\n",
    "name: Queue                     <- This is the atomic model name, which will become in python the class name you'll instance.\n",
    "input_ports: job, ready         <- comma-separated-list of input ports names\n",
    "output_ports: job_status        <- comma-separated-list of output ports names\n",
    "*/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and analyzing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, back to our model. We are going to work with atomics named **NodeN**, with $1 <= n <= 20$, where NodeN is a vertex with N different input, and output ports. In other words, the *Node5* atomic model has 5 input ports named *in0* to *in4*, and the same for *outM*.\n",
    "\n",
    "According to the model description above, this changes the way in which the *infection* part of the node's behaviour work. Notice that it's not related to the degree-graph-sense of the node, since by using a Node1 (just one input and output port), we can make a vertex of degree 50.\n",
    "\n",
    "We will describe to approaches for building the network (graph) of individuals we want to simulate:\n",
    "- A pure pringles approach\n",
    "- A NetworkX - Pringles mixup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure pringles\n",
    "\n",
    "For this approach, we will build a fully-connected-graph. For this, we will use just pringles, and leverage the way in which we built our Node atomics. \n",
    "\n",
    "First, we will a build a function for building a $N$ nodes fully-connected top model, also propagating the parameters of both the $P(infection)$, *infection_prob*, and the inter-infections exponential time mean, *exp_lambda*.\n",
    "\n",
    "Then, we will instantiate a sample model (the parameters should be nonsense), and run a simple simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complete_graph_of_nodes(n, exp_lambda, infection_rate):\n",
    "    # Instantiate 'n' Node1 atomics. Remember that his ones just have one input port (in0), and one ouput (out0)\n",
    "    nodes = [r.Node1(\"node%d\" % (i), exp_lambda=exp_lambda, infection_prob=infection_rate) for i in range(n)]\n",
    "    # This will be our top coupled, called 'top' obviously, and will all the nodes we created above\n",
    "    graph = Coupled(\"top\", nodes)\n",
    "    # For each pair of different nodes we created, we will connect their only ports.\n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            if i != j:\n",
    "                graph.add_coupling(nodes[i].get_port(\"out0\"), nodes[j].get_port(\"in0\"))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's instantiate a sample 5 vertexes SIR model.\n",
    "sample_five_node_graph = build_complete_graph_of_nodes(5, 2, .5)\n",
    "# NOTE-INTERNAL: I have to run the cell twice in order for Diagrammer for rendering the HTML-representation. Also, sometimes is rendered horribly.\n",
    "# Notice that we binded Jupyter's rich display environment with our Model implementation.\n",
    "sample_five_node_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate the Simulation we are about to run. In case you didn't notice, Simulation objects are immutable once instantiated. \n",
    "# This helps having one container for the whole simulation you've ran, and will make things be more ordered.\n",
    "\n",
    "# The simulation will be of our recently-created 5-node top model, and will be ran for 60 seconds. You can check out the other VirtualTime helpers, or use the main constructor.\n",
    "sample_simulation = Simulation(sample_five_node_graph, VirtualTime.of_minutes(60))\n",
    "sample_simulation_results = simulator.run_simulation(sample_simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the simulation, we obtain a **SimulationResult** object. This contains among other things, a *pandas dataframe*  for each model participating in the simulation, with its parsed logs. **For the moment, just the output and external transitions are recorded.**\n",
    "\n",
    "This collection of dataframes is accessed as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_simulation_results.logs_dfs is a Dict[model_name: str, data: pandas.Dataframe]\n",
    "sample_simulation_results.logs_dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, because this model involves non-deterministic behaviour, it's possible you will have to run the simulation several times in order to observe some behaviour. At least with a 5-node model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_model_name = None\n",
    "for model_name in sample_simulation_results.logs_dfs.keys():\n",
    "    if sample_simulation_results.logs_dfs[model_name].size > 0 \\\n",
    "        and model_name.startswith('node'):\n",
    "        non_empty_model_name = model_name\n",
    "sample_simulation_results.logs_dfs[non_empty_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can access the results of the simulation, lets do a little of dataframe processing. We will abstract all this in some function, so we can later re-use it with the *NetworkX* approach.\n",
    "\n",
    "First, let's concatenate all node-models dataframes into one, and sort it by the time the transitions occurred at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # We will do some dataframe processing\n",
    "import matplotlib.pyplot as plt # We will build some custom plots, leveraging pringles vtime autoformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_nodes_results(results):\n",
    "    # Concatenating all nodes external transitions\n",
    "    nodes_external_transitions = pd.concat([results.logs_dfs[node_id] for node_id in results.logs_dfs.keys() if node_id.startswith(\"node\")])\n",
    "    # Sort it by Vtime. This is possible since VirtualTime implements all comparison and equality operators in Python\n",
    "    nodes_external_transitions = nodes_external_transitions.sort_values(by=[\"time\"])\n",
    "    return nodes_external_transitions\n",
    "\n",
    "nodes_external_transitions = merge_all_nodes_results(sample_simulation_results)\n",
    "nodes_external_transitions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze some simple behaviour of the model, for example, the accumulated distribution of infections over time. \n",
    "We know that an external transition of a *HEALTHY* node occurs when an infected one sends a message to the former one.\n",
    "\n",
    "Let's drop all unused data in the dataframe, and calculate how many infection get accumulated over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accumulated_infections(nodes_external_transitions):\n",
    "    # Count the quantity of external transition over time\n",
    "    infections_count = nodes_external_transitions.groupby(\"time\").count()\n",
    "    # Drop all unused columns of dataframe\n",
    "    infections_count = infections_count.drop([0, 1, \"message_type\", \"model_origin\", \"port\", \"model_dest\"], axis=1)\n",
    "    infections_count = infections_count.rename({\"value\":\"infections_count\"}, axis=1)\n",
    "    \n",
    "    # Since all infection are separated into buckets by its occurring time, let's accumulate them\n",
    "    accum_infections = [0] * len(list(infections_count.infections_count))\n",
    "    for i, c in enumerate(list(infections_count.infections_count)):\n",
    "        if i == 0:\n",
    "            accum_infections[i] = c\n",
    "        else:\n",
    "            accum_infections[i] = accum_infections[i-1] + c\n",
    "            \n",
    "    # Also, let's obtain the time of each accumulation bucket\n",
    "    times = list(infections_count.index)\n",
    "    \n",
    "    return times, accum_infections\n",
    "\n",
    "infection_times, accum_infections = calculate_accumulated_infections(nodes_external_transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we calculated the infection accumulated over time, let's draw a plot of them. \n",
    "\n",
    "Since the X-axis we want is time, and we are representing it as VirtualTime, we need some way to map this to matplotlib. Fortunately, pringles come with a custom Matplotlib axes generator, which knows how to automatically render and convert the VirtualTime time repsentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pringles.utils import new_vtime_aware_axes\n",
    "\n",
    "def plot_infections_over_time(times, infections, ax = None):\n",
    "    if ax is None:\n",
    "        # New axes\n",
    "        ax = new_vtime_aware_axes()\n",
    "    # Let's set the x-axis limit to the max time we've found, plus a little more.\n",
    "    ax.set_xlim(0, max([float(vtime) for vtime in times])+float(VirtualTime.from_number(1000)))\n",
    "    # Plot!\n",
    "    ax.plot(times, infections, 'o')\n",
    "    ax\n",
    "    \n",
    "plot_infections_over_time(infection_times, accum_infections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add restrospective here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration model graph generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second approach consists of leveraging *networkx* random graph generation capabilites, interfacing this with *pringles* to build a model from that graph's description, and simulating the same.\n",
    "\n",
    "The method used for generating a random graph is called **configuration model**. The explanation of this method is outside the scope of this document, but for reference, lets just quote [wikipedia](https://en.wikipedia.org/wiki/Configuration_model).\n",
    "\n",
    "For this example, the graph generation code has been hidden inside the *RandomGraphGenerator* class, since this is all the random plus networkx boilerplate. You are encouraged to take a look either way. For this doc sake, the only thing you have to be aware of is that the generated graph is a [NetworkX Graph](https://networkx.github.io/documentation/stable/reference/classes/graph.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.graphs import RandomGraphGenerator\n",
    "\n",
    "random_graph = RandomGraphGenerator(75).generate()\n",
    "random_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our graph, using the API exposed by networkx, let's build a coupled model with pringles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import networkx as nx\n",
    "\n",
    "def build_graph_model_from_nx_graph(graph: nx.Graph, exp_lambda, infection_rate):\n",
    "    # Fist, for each vertex in the graph, we acquire the degree of that node\n",
    "    nodes_degrees = [graph.degree(i) for i in range(len(graph.nodes))]\n",
    "    max_degree = max(nodes_degrees)\n",
    "    # Just for checking, we fail if some vertex has degree over 20 (our biggest Node atomic has that value)\n",
    "    if max_degree > 20:\n",
    "        raise Exception(\"Do no have models of degree above 20\")\n",
    "    # We create a Node atomic of degree 'd', for each vertex in the graph\n",
    "\n",
    "    # Notice how we fetch from the registry the Atomic's classes by their name, this is helpful if we want some custom mapping\n",
    "    # from a any value of type D, to an Atomic class. Obviously in that case, we need to encode that D characteristic inside the \n",
    "    # atomic class name.\n",
    "    nodes = [r.get_by_name(\"Node%d\" % (degree))(\"node%d\" % (i), exp_lambda=exp_lambda, infection_prob=infection_rate) \n",
    "             for i, degree in enumerate(nodes_degrees)]\n",
    "\n",
    "    # Our top model\n",
    "    pringles_graph = Coupled(\"top\", nodes)\n",
    "    \n",
    "    # Some boilerplate code for remembering the last assigned port in each node, so we don't overwrite any of them\n",
    "    _last_out_node = {}\n",
    "    _last_in_node = {}\n",
    "    def do_get_last_port(u: int, dic: Dict[int, int], portname: str):\n",
    "        if u not in dic:\n",
    "            dic[u] = 0\n",
    "            return portname + \"0\"\n",
    "        else:\n",
    "            last = dic[u]\n",
    "            dic[u] = last+1\n",
    "            return portname + \"%d\" % (last+1)\n",
    "    def last_out_port(u):\n",
    "        return do_get_last_port(u, _last_out_node, \"out\")\n",
    "    def last_in_port(u):\n",
    "        return do_get_last_port(u, _last_in_node, \"in\")\n",
    "    \n",
    "    # Now, for each edge in the graph, we add a coupling between those two nodes. Here we are using thos 'last_out_port'\n",
    "    # and 'last_int_port' helpers.\n",
    "    for u,v in graph.edges():\n",
    "        pringles_graph.add_coupling(nodes[u].get_port(last_out_port(u)), nodes[v].get_port(last_in_port(v)))\n",
    "    \n",
    "    # All done!\n",
    "    return pringles_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build a DEVS model from our randomly-generated graph, using the same parameters as the first example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graph_coupled = build_graph_model_from_nx_graph(random_graph, 2, .6)\n",
    "random_graph_simulation = Simulation(random_graph_coupled, VirtualTime.of_minutes(10))\n",
    "random_graph_results = simulator.run_simulation(random_graph_simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just checking the captured logs\n",
    "random_graph_results.logs_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And checking one of them that's non emtpy\n",
    "non_empty_model_name = None\n",
    "for model_name in random_graph_results.logs_dfs.keys():\n",
    "    if random_graph_results.logs_dfs[model_name].size > 0 \\\n",
    "        and model_name.startswith('node'):\n",
    "        non_empty_model_name = model_name\n",
    "\n",
    "random_graph_results.logs_dfs[non_empty_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = merge_all_nodes_results(random_graph_results)\n",
    "times, infections = calculate_accumulated_infections(merged_results)\n",
    "plot_infections_over_time(times, infections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yapa: *Parameter Sweeping*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter sweeping consists on exploring some test or trial, with similar configuration, by varying or chaning some parameter/s one/many at a time. With pringles this becomes easy, since it just means definfing a function that take the paremeters and generates a model, and from that point on, its just running the simulation.\n",
    "\n",
    "Let's run the our previous randomly-generated graph model, exploring how the infection rate, and the mean of the inter-infection times affect the infections distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets wrap all the plot generating boilerplate in just one function\n",
    "def plot_accumulated_infections_from_result_in_axes(result, ax):\n",
    "    merged_results = merge_all_nodes_results(result)\n",
    "    times, infections = calculate_accumulated_infections(merged_results)\n",
    "    plot_infections_over_time(times, infections, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are working with custom Matplotlib axes, we can still decorate them with the VTime formatter\n",
    "from pringles.utils import vtime_decorate\n",
    "import numpy as np\n",
    "\n",
    "# This will be the ranges we'll cover\n",
    "infection_rates = np.arange(.25, 1, .1)\n",
    "exp_means = np.arange(1, 5, 1)\n",
    "# DEBUG\n",
    "print(f'Will cover this infection rates: {infection_rates}, and exp means: {exp_means}')\n",
    "\n",
    "# Defien the subplots\n",
    "plt.tight_layout(h_pad=3)\n",
    "fig, axes = plt.subplots(nrows=len(infection_rates), ncols=len(exp_means), figsize=(20,10), sharex=True)\n",
    "\n",
    "# Going through each (infection_rate,mean) pair\n",
    "for index, infection_rate in enumerate(infection_rates):\n",
    "    for index2, mean in enumerate(exp_means):\n",
    "        # Build the same random_graph with our custom infection rate\n",
    "        random_graph_coupled = build_graph_model_from_nx_graph(random_graph, mean, infection_rate)\n",
    "\n",
    "        # Run the simulation\n",
    "        # DEBUG\n",
    "        print(f'Running simulation for infection_rate = {infection_rate}, exp_lambda = {mean}')\n",
    "        random_graph_simulation = Simulation(random_graph_coupled, VirtualTime.of_minutes(10))\n",
    "        random_graph_results = simulator.run_simulation(random_graph_simulation)\n",
    "        \n",
    "        # Select current axes\n",
    "        current_axes = axes[(index, index2)]\n",
    "        # Decorate axes\n",
    "        vtime_decorate(current_axes)\n",
    "        current_axes.set_title('ir = %.2f mean=%d' % (infection_rate, mean))\n",
    "\n",
    "        # Plot all results\n",
    "        plot_accumulated_infections_from_result_in_axes(random_graph_results, current_axes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
